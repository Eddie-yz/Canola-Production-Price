{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(filename):\n",
    "    ret = {}\n",
    "    val = []\n",
    "    with open(filename, newline='', encoding = 'utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            region, start_date, end_date = row['Region'], row['Start Date'], row['End Date']\n",
    "            if row['Deliveries'] != '':\n",
    "                d = float(row['Deliveries'])\n",
    "            else:\n",
    "                d = 0\n",
    "            if row['Prices'] != '':\n",
    "                p = float(row['Prices'])\n",
    "            else:\n",
    "                p = 0\n",
    "            ret[(region, start_date, end_date)] = (d, p)\n",
    "            val.append([d,p])\n",
    "    return ret, val\n",
    "\n",
    "_, pred = load_labels(\"baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2submission(pred):\n",
    "    sol = open(\"solution/solution.csv\", newline='', encoding='utf-8',mode='w')\n",
    "    sam = open(\"sample.csv\", newline='', encoding='utf-8',mode='r')\n",
    "    bl = open(\"baseline.csv\", newline='', encoding='utf-8',mode='r')\n",
    "    bl.readline()\n",
    "    sol.write(sam.readline())\n",
    "    con = sam.readlines()\n",
    "    con_bl = bl.readlines()\n",
    "    for ind, row in enumerate(con):\n",
    "        row = row.strip().split(',')\n",
    "        row_bl = con_bl[ind].strip().split(',')\n",
    "        row[3] = str(max(pred[ind][0],0))\n",
    "        row[4] = row_bl[4]\n",
    "        #row[4] = str(pred[ind][1])\n",
    "        sol.write(\",\".join(row) + \"\\n\")\n",
    "    sol.close()\n",
    "    sam.close()\n",
    "    bl.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanolaData(object):\n",
    "    def __init__(self, loadfile):\n",
    "        self.region_startdate = {}\n",
    "        self.region_startdate[\"Alberta\"] = 2001\n",
    "        self.region_startdate[\"British Columbia\"] = 2001\n",
    "        self.region_startdate[\"Manitoba\"] = 2001\n",
    "        self.region_startdate[\"Ontario\"] = 2001\n",
    "        self.region_startdate[\"Saskatchewan\"] = 2001\n",
    "        self.region_startdate[\"Québec\"] = 2001\n",
    "        self.region_list = [\"Alberta\", \"British Columbia\", \"Manitoba\", \"Ontario\", \"Québec\", \"Saskatchewan\"]\n",
    "        self.region_onthot = {}\n",
    "        self.region_onthot[\"Alberta\"] = [1,0,0,0,0,0]\n",
    "        self.region_onthot[\"British Columbia\"] = [0,1,0,0,0,0]\n",
    "        self.region_onthot[\"Manitoba\"] = [0,0,1,0,0,0]\n",
    "        self.region_onthot[\"Ontario\"] = [0,0,0,1,0,0]\n",
    "        self.region_onthot[\"Saskatchewan\"] = [0,0,0,0,1,0]\n",
    "        self.region_onthot[\"Québec\"] = [1,0,0,0,0,1]\n",
    "        self.season_onthot = {}\n",
    "        self.season_onthot[1] = [0,0,0,1]\n",
    "        self.season_onthot[2] = [0,0,0,1]\n",
    "        self.season_onthot[3] = [0,0,0,1]\n",
    "        self.season_onthot[4] = [0,0,0,1]\n",
    "        self.season_onthot[5] = [1,0,0,0]\n",
    "        self.season_onthot[6] = [0,1,0,0]\n",
    "        self.season_onthot[7] = [0,1,0,0]\n",
    "        self.season_onthot[8] = [0,0,1,0]\n",
    "        self.season_onthot[9] = [0,0,1,0]\n",
    "        self.season_onthot[10] = [0,0,1,0]\n",
    "        self.season_onthot[11] = [0,0,0,1]\n",
    "        self.season_onthot[12] = [0,0,0,1]\n",
    "\n",
    "        if loadfile is False:\n",
    "            self.delivery = self.targetDataLoader(\"Challenge_Data/1. Target Variables/Canada_Canola_Producer_Deliveries.csv\")\n",
    "            self.price = self.targetDataLoader(\"Challenge_Data/1. Target Variables/Canada_Canola_Producer_Prices.csv\")\n",
    "            self.harvested_area = self.yearlyDataLoader(\"Challenge_Data/2. Other Canola Production Data/Canada_Canola_Harvested_Area.csv\")\n",
    "            self.yield_value = self.yearlyDataLoader(\"Challenge_Data/2. Other Canola Production Data/Canada_Canola_Yield.csv\")\n",
    "            self.rainfall_data = self.rainfallDataLoader()\n",
    "            self.temp_data = self.temperatureDataLoader()\n",
    "            save_dict = {\"delivery\": self.delivery,\n",
    "                        \"price\": self.price,\n",
    "                        \"harvested_area\": self.harvested_area,\n",
    "                        \"yield_value\": self.yield_value,\n",
    "                        \"rainfall_data\": self.rainfall_data,\n",
    "                        \"temp_data\": self.temp_data}\n",
    "            with open(\"dataprepared.pkl\",\"wb\") as f:\n",
    "                pickle.dump(save_dict, f)\n",
    "        \n",
    "        else:\n",
    "            with open(\"dataprepared.pkl\",\"rb\") as f:\n",
    "                savedict = pickle.load(f)\n",
    "            self.delivery = savedict[\"delivery\"]\n",
    "            self.price = savedict[\"price\"]\n",
    "            self.harvested_area = savedict[\"harvested_area\"]\n",
    "            self.yield_value = savedict[\"yield_value\"]\n",
    "            self.rainfall_data = savedict[\"rainfall_data\"]\n",
    "            self.temp_data = savedict[\"temp_data\"]\n",
    "\n",
    "\n",
    "    def deliveryDataCombine(self, history_length=2, for_train=True, harvested=False, yields=False, rainfall=False, temp=False):\n",
    "        start_year = np.max(list(self.region_startdate.values())) + history_length\n",
    "        data = []\n",
    "        for year in range(start_year, 2019):\n",
    "            for region in self.region_list:\n",
    "                region_feature = self.region_onthot[region]\n",
    "                for month in range(12):\n",
    "                    season_feature = self.season_onthot[month+1]\n",
    "                    x_delivery = []\n",
    "                    for k in range(1, history_length+1):\n",
    "                        x_delivery.append(self.delivery[region][year-k][month])\n",
    "                    x_delivery.extend(self.rainfall_data[region][year][month][:2])\n",
    "                    x_delivery.extend(self.temp_data[region][year][month][:2])\n",
    "                    x_delivery.extend(region_feature)\n",
    "                    x_delivery.extend(season_feature)\n",
    "                    y_delivery = self.delivery[region][year][month]\n",
    "                    data.append([x_delivery, y_delivery])\n",
    "        \n",
    "        if for_train:\n",
    "            return data[:-72], data[-72:]\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "    def to_predict(self, history_length):\n",
    "        data = []\n",
    "        year = 2019\n",
    "        for region in self.region_list:\n",
    "            region_feature = self.region_onthot[region]\n",
    "            for month in range(12):\n",
    "                season_feature = self.season_onthot[month+1]\n",
    "                x_delivery = []\n",
    "                for k in range(1, history_length+1):\n",
    "                    x_delivery.append(self.delivery[region][year-k][month])\n",
    "                x_delivery.extend(self.rainfall_data[region][year][month][:2])\n",
    "                x_delivery.extend(self.temp_data[region][year][month][:2])\n",
    "                x_delivery.extend(region_feature)\n",
    "                x_delivery.extend(season_feature)\n",
    "                data.append(x_delivery)\n",
    "        return data\n",
    "    \n",
    "    def targetDataLoader(self, filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        ret = defaultdict(dict)\n",
    "        for region in tqdm(self.region_startdate):\n",
    "            y = self.region_startdate[region]\n",
    "            for year in range(y, 2019):\n",
    "                data4year = []\n",
    "                for month in range(1,13):\n",
    "                    date = str(year) + \"-\" + \"{:0>2d}\".format(month)\n",
    "                    v = data[(data[\"Region\"] == region) & \n",
    "                            (data[\"Start Date\"].str.contains(date))][\"Value\"].values\n",
    "                    try:\n",
    "                        data4year.append(float(v))\n",
    "                    except:\n",
    "                        data4year.append(0.0)\n",
    "                ret[region][year] = data4year\n",
    "        return ret\n",
    "\n",
    "    def yearlyDataLoader(self, filename):\n",
    "        data = pd.read_csv(filename)\n",
    "        ret = defaultdict(dict)\n",
    "        for region in tqdm(self.region_startdate):\n",
    "            y = self.region_startdate[region]\n",
    "            for year in range(y, 2019):\n",
    "                v = data[(data[\"Region\"] == region) & \n",
    "                        (data[\"Start Date\"].str.contains(str(year)))][\"Value\"].values\n",
    "                try:\n",
    "                    ret[region][year] = float(v)\n",
    "                except:\n",
    "                    ret[region][year] = 0\n",
    "        return ret\n",
    "\n",
    "    def rainfallDataLoader(self):\n",
    "        '''if a month of data is missing, replace it with the data from \\n \n",
    "        the same region, same month of the previous year'''\n",
    "            \n",
    "        dirname = \"Challenge_Data/4. Spatio-Temporal & Weather Data/Rainfall/\"\n",
    "        ret = defaultdict(dict)\n",
    "        for name in tqdm(os.listdir(dirname)):\n",
    "            filename = dirname + name\n",
    "            year = int((name.strip().split('.')[0]).split('_')[-1])\n",
    "            if year == 2000 or year == 2020:\n",
    "                continue\n",
    "            \n",
    "            data = pd.read_csv(filename)\n",
    "            for region in self.region_startdate:\n",
    "                ret[region][year] = []\n",
    "                for month in range(1, 13):\n",
    "                    date = str(year) + \"-\" + \"{:0>2d}\".format(month)\n",
    "                    monthly_detail = np.array(data[(data[\"start_date\"].str.contains(date)) &\n",
    "                                                (data[\"region_name\"] == region)][\"value\"])\n",
    "                    try:\n",
    "                        ret[region][year].append([np.mean(monthly_detail), np.std(monthly_detail),\n",
    "                                            np.min(monthly_detail), np.max(monthly_detail)])\n",
    "                    except:\n",
    "                        print (region, date)\n",
    "                        ret[region][year].append(ret[region][year-1][month-1])\n",
    "        return ret\n",
    "\n",
    "    def temperatureDataLoader(self):\n",
    "        '''if a month of data is missing, replace it with the data from \\n \n",
    "        the same region, same month of the previous year'''\n",
    "        \n",
    "        dirname = \"Challenge_Data/4. Spatio-Temporal & Weather Data/Temperature/\"\n",
    "        ret = defaultdict(dict)\n",
    "        for name in tqdm(os.listdir(dirname)):\n",
    "            filename = dirname + name\n",
    "            year = int((name.strip().split('.')[0]).split('_')[-1])\n",
    "            if year == 2000 or year == 2020:\n",
    "                continue\n",
    "            \n",
    "            data = pd.read_csv(filename)\n",
    "            for region in self.region_startdate:\n",
    "                ret[region][year] = []\n",
    "                for month in range(1, 13):\n",
    "                    date = str(year) + \"-\" + \"{:0>2d}\".format(month)\n",
    "                    monthly_detail = np.array(data[(data[\"start_date\"].str.contains(date)) &\n",
    "                                                (data[\"region_name\"] == region)][\"value\"])\n",
    "                    monthly_detail = monthly_detail[~np.isnan(monthly_detail)]\n",
    "\n",
    "                    try:\n",
    "                        ret[region][year].append([np.mean(monthly_detail), np.std(monthly_detail),\n",
    "                                            np.min(monthly_detail), np.max(monthly_detail)])\n",
    "                    except:\n",
    "                        print (region, date)\n",
    "                        ret[region][year].append(ret[region][year-1][month-1])\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pred, gt):\n",
    "    num = 0\n",
    "    relative = 0.0\n",
    "    for (p,y) in zip(pred, gt):\n",
    "        if y == 0:\n",
    "            continue\n",
    "        num += 1\n",
    "        relative += (abs(p-y)/y)\n",
    "    relative /= num\n",
    "    return max(0, 1-relative)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataObj = CanolaData(loadfile=True)\n",
    "deliTrain, deliVal = dataObj.deliveryDataCombine(history_length=2, for_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(dataObj.to_predict(history_length=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([item[0] for item in deliTrain])\n",
    "y_train = np.array([item[1] for item in deliTrain]).reshape((-1,1))\n",
    "X_val = np.array([item[0] for item in deliVal])\n",
    "y_val = np.array([item[1] for item in deliVal]).reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 16)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class CanolaModel(nn.Module):\n",
    "    def __init__(self, history_length):\n",
    "        super(CanolaModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 1)\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "    def forward(self, X):\n",
    "        out = self.fc1(X)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = CanolaModel(history_length=2)\n",
    "naive = naive.float()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(naive.parameters(), lr=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4d6f4a181145d987dd42f4c8331ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48950.07626922153\n",
      "47539.92213928556\n",
      "48736.28044561236\n",
      "46894.76654193332\n",
      "45947.11791893663\n",
      "49629.3022090658\n",
      "47214.765831112585\n",
      "46745.70945133826\n",
      "46920.8626319563\n",
      "48271.41243671874\n",
      "47337.82687774919\n",
      "47691.08692140668\n",
      "46916.20053695772\n",
      "46968.43156859477\n",
      "48581.726978348364\n",
      "47283.14139357628\n",
      "47488.2237428089\n",
      "46758.276990996026\n",
      "47862.18926283209\n",
      "46151.26597486204\n",
      "47819.80302438692\n",
      "48344.650848761754\n",
      "47716.34505469534\n",
      "46342.57045190732\n",
      "50939.11621737348\n",
      "47473.42014433543\n",
      "46949.19575658904\n",
      "46555.73072788627\n",
      "48104.752873673264\n",
      "49025.46673854545\n",
      "47199.51150505631\n",
      "46962.83974291042\n",
      "49058.99042669667\n",
      "48404.35348025251\n",
      "46871.374667774304\n",
      "48794.8685802495\n",
      "49025.08580074222\n",
      "46608.828720798316\n",
      "48056.739418603756\n",
      "49148.09001562684\n",
      "46729.320519996574\n",
      "47862.86631515556\n",
      "45897.12979082708\n",
      "46907.54721166469\n",
      "47886.87618267624\n",
      "47364.27599418075\n",
      "47503.27375943925\n",
      "47894.1557184449\n",
      "47139.32233885659\n",
      "48397.49051264481\n",
      "46754.46360560523\n",
      "47314.32038828532\n",
      "48027.23397646304\n",
      "47068.24374417023\n",
      "48393.928902732005\n",
      "48463.15853202343\n",
      "49564.64470972132\n",
      "46719.1923389841\n",
      "48024.56325058937\n",
      "48973.84659704809\n",
      "47440.12430859142\n",
      "47209.97739655883\n",
      "48219.127885694856\n",
      "49631.71355027976\n",
      "46773.43182429208\n",
      "47940.70591685507\n",
      "48803.48187225572\n",
      "47549.09760709869\n",
      "47999.993965104775\n",
      "47709.840709871714\n",
      "46821.819090262165\n",
      "49197.84938850226\n",
      "47794.13575165183\n",
      "49641.716371075316\n",
      "46927.13165590498\n",
      "49618.706049302775\n",
      "47596.56686367812\n",
      "48704.3087772705\n",
      "48055.66110262341\n",
      "48648.27932304629\n",
      "47185.49570984664\n",
      "48454.916032985406\n",
      "47603.27191930877\n",
      "48142.71873213803\n",
      "47569.832516497154\n",
      "47183.81832153709\n",
      "48540.18682292479\n",
      "47496.493538014096\n",
      "51356.15651990219\n",
      "49096.97020101547\n",
      "49533.83456284028\n",
      "47559.92021358455\n",
      "49261.739852147635\n",
      "48885.32077152641\n",
      "46912.70261389591\n",
      "47322.60728987941\n",
      "47902.92916629226\n",
      "46602.34299324353\n",
      "48349.01251838119\n",
      "48223.689130451065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    ids = np.random.permutation(X_train.shape[0])\n",
    "    epoch_loss = 0.0\n",
    "    for sample_id in ids:\n",
    "        x = Variable(torch.from_numpy(X_train[sample_id,:12]))\n",
    "        y = Variable(torch.from_numpy(y_train[sample_id]))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = naive(x.float())\n",
    "        loss = criterion(pred, y.float())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print (epoch_loss/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 8.2749e-01,  2.8612e-01, -1.8275e+01,  4.3046e+01, -1.1449e+00,\n",
       "          1.1786e+01,  2.1354e+01, -9.2915e+01, -6.3722e+01, -1.6358e+02,\n",
       "          3.7508e+02, -1.2444e+02]], requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.08742318521516"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = naive(Variable(torch.from_numpy(X_val[:,:12])).float())\n",
    "score(y_pre.detach().numpy().flatten(), y_val.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = naive(Variable(torch.from_numpy(X_test[:,:12])).float())\n",
    "#score(y_pre.detach().numpy().flatten(), y_val.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "write2submission(y_pre.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/3_4_4.pkl\", 'wb') as f:\n",
    "    pickle.dump(naive, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.352216419170066"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = naive(Variable(torch.from_numpy(X_train[-72:,:11])).float())\n",
    "score(y_pre.detach().numpy().flatten(), y_train[-72:].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delivery baseline for 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.375134469278066\n"
     ]
    }
   ],
   "source": [
    "relative_error = 0.0\n",
    "num = 0\n",
    "for region in region_list:\n",
    "    for month in range(12):\n",
    "        if dataObj.delivery[region][2018][month] == 0:\n",
    "            continue\n",
    "        error = abs(dataObj.delivery[region][2018][month] - dataObj.delivery[region][2017][month])/dataObj.delivery[region][2018][month]  \n",
    "        relative_error += error\n",
    "        num += 1\n",
    "relative_error /= num\n",
    "score = max(0, 1-relative_error) * 100\n",
    "print (score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
